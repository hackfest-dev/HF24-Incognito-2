{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "aai.settings.api_key = \"9dc0beed5a1b4f8ebb6b32694b400171\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da75e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import wave\n",
    "import threading\n",
    "\n",
    "# Global variable to control recording\n",
    "recording = False\n",
    "\n",
    "def record_audio(filename):\n",
    "    global recording\n",
    "    print(\"Recording started. Press 'Enter' to stop recording...\")\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    audio_data = []  # Initialize audio data array\n",
    "\n",
    "    # Start recording\n",
    "    recording = True\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    while recording:\n",
    "        # Record audio in chunks\n",
    "        data = stream.read(CHUNK)\n",
    "        audio_data.append(data)\n",
    "\n",
    "    # Stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    print(\"Recording stopped.\")\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(audio_data))\n",
    "    wf.close()\n",
    "\n",
    "def start_recording(filename):\n",
    "    global recording\n",
    "    if not recording:\n",
    "        recording = True\n",
    "        threading.Thread(target=record_audio, args=(filename,), daemon=True).start()\n",
    "\n",
    "def stop_recording():\n",
    "    global recording\n",
    "    recording = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31feab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter file namelak.wav\n"
     ]
    }
   ],
   "source": [
    "audio_url =input(\"enter file name\")\n",
    "while True:\n",
    "    user_input = input(\"Press 'r' to start recording, 's' to stop recording, or 'q' to quit: \").lower()\n",
    "    if user_input == 'r':\n",
    "        start_recording(audio_url)\n",
    "    elif user_input == 's':\n",
    "        stop_recording()\n",
    "    elif user_input == 'q':\n",
    "        break\n",
    "else:\n",
    "    print(\"Invalid choice. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from mutagen.mp3 import MP3\n",
    "from mutagen.mp4 import MP4\n",
    "from mutagen.flac import FLAC\n",
    "from mutagen.wavpack import WavPack\n",
    "from mutagen.oggvorbis import OggVorbis\n",
    "\n",
    "def get_audio_duration(filename):\n",
    "    if filename.endswith('.mp3'):\n",
    "        audio = MP3(filename)\n",
    "    elif filename.endswith('.mp4'):\n",
    "        audio=MP4(filename)\n",
    "    elif filename.endswith('.flac'):\n",
    "        audio = FLAC(filename)\n",
    "    elif filename.endswith('.wv'):\n",
    "        audio = WavPack(filename)\n",
    "    elif filename.endswith('.ogg'):\n",
    "        audio = OggVorbis(filename)\n",
    "    elif filename.endswith('.wav'):\n",
    "        with wave.open(filename, 'rb') as audio_file:\n",
    "            frames = audio_file.getnframes()\n",
    "            rate = audio_file.getframerate()\n",
    "            duration_seconds = frames / float(rate)\n",
    "        return duration_seconds\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported audio format\")\n",
    "\n",
    "    duration_seconds = audio.info.length\n",
    "    return duration_seconds\n",
    "\n",
    "def format_duration(duration):\n",
    "    hours = int(duration / 3600)\n",
    "    minutes = int((duration % 3600) / 60)\n",
    "    seconds = int(duration % 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "audio_file = audio_url \n",
    "duration_seconds = get_audio_duration(audio_file)\n",
    "duration_formatted = format_duration(duration_seconds)\n",
    "print(\"Audio duration:\", duration_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219aa0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"do you want speaker labels?\")\n",
    "print(\"NOTE: number of speakers should be more than 1 for speaker labels to be implemented\")\n",
    "choice=input()\n",
    "speaker_label= bool(choice=='yes')\n",
    "print(\"do you want text content to be in paragraphs or sentences?\")\n",
    "choice1=input()\n",
    "para_label=bool(choice1=='paragraphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e38614",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"do you want to transcribe a portion of your file?\")\n",
    "choice2=input()\n",
    "check=bool(choice2=='yes')\n",
    "if check:\n",
    "    start=input(\"enter start time(hh:mm:ss)\")\n",
    "    start_hours,start_minutes,start_seconds = map(int, start.split(':'))\n",
    "    end=input(\"enter end time(hh:mm:ss)\")\n",
    "    end_hours,end_minutes,end_seconds = map(int, end.split(':'))\n",
    "else:\n",
    "    start_hours,start_minutes,start_seconds=0,0,0\n",
    "    end_hours,end_minutes,end_seconds=map(int, duration_formatted.split(':'))\n",
    "start_milliseconds = (start_hours * 60 * 60 * 1000) + (start_minutes * 60 * 1000) + (start_seconds * 1000)\n",
    "end_milliseconds = (end_hours * 60 * 60 * 1000) + (end_minutes * 60 * 1000) + (end_seconds * 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(url,speaker_label, para_label, start_milliseconds, end_milliseconds):\n",
    "    config = aai.TranscriptionConfig(auto_highlights=True,speaker_labels=speaker_label, audio_start_from=start_milliseconds, audio_end_at=end_milliseconds)\n",
    "    transcriber = aai.Transcriber(config=config)\n",
    "    transcript = transcriber.transcribe(url)\n",
    "\n",
    "    if transcript.status == aai.TranscriptStatus.error:\n",
    "        print(transcript.error)\n",
    "        return \"\"\n",
    "    else:\n",
    "        formatted_transcript = \"\"  \n",
    "        highlights=\"\"\n",
    "        \n",
    "        for result in transcript.auto_highlights.results:\n",
    "            highlights+= f\"Highlight: {result.text}, Count: {result.count}, Rank: {result.rank}, Timestamps: {result.timestamps}\\n\"\n",
    "            \n",
    "        if speaker_label:\n",
    "            speakers = set(utterance.speaker for utterance in transcript.utterances)\n",
    "            if len(speakers) == 1:\n",
    "                if para_label:\n",
    "                    paragraphs = transcript.get_paragraphs()\n",
    "                    for paragraph in paragraphs:\n",
    "                        formatted_transcript += paragraph.text + \"\\n\"\n",
    "                else:\n",
    "                    sentences = transcript.get_sentences()\n",
    "                    for sentence in sentences:\n",
    "                        formatted_transcript += sentence.text + \"\\n\"\n",
    "            else:\n",
    "                for utterance in transcript.utterances:\n",
    "                    formatted_transcript += f\"Speaker {utterance.speaker}: \"\n",
    "                    sentences = nltk.sent_tokenize(utterance.text)\n",
    "                    if para_label:\n",
    "                        paragraphs = [' '.join(sentences[i:i+2]) for i in range(0, len(sentences), 2)]\n",
    "                        for paragraph in paragraphs:\n",
    "                            formatted_transcript += paragraph + \"\\n\"\n",
    "                    else:\n",
    "                        for sentence in sentences:\n",
    "                            formatted_transcript += sentence + \"\\n\"\n",
    "        else:\n",
    "            if para_label:\n",
    "                paragraphs = transcript.get_paragraphs()\n",
    "                for paragraph in paragraphs:\n",
    "                    formatted_transcript += paragraph.text + \"\\n\"  \n",
    "            else:\n",
    "                sentences = transcript.get_sentences()\n",
    "                for sentence in sentences:\n",
    "                    formatted_transcript += sentence.text + \"\\n\"  \n",
    "\n",
    "        return formatted_transcript,highlights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text,highlights = speech_to_text(audio_url,speaker_label, para_label, start_milliseconds, end_milliseconds)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
